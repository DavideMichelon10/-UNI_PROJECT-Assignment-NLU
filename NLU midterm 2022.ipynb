{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb67ba8d",
   "metadata": {},
   "source": [
    "# NLU: Mid-Term Assignment 2022\n",
    "### Description\n",
    "In this notebook, we ask you to complete four main tasks to show what you have learnt during the NLU labs. Therefore, to complete the assignment please refer to the concepts, libraries and other materials shown and used during the labs. The last task is not mandatory, it is a *BONUS* to get an extra mark for the laude. \n",
    "\n",
    "### Instructions\n",
    "- **Dataset**: in this notebook, you are asked to work with the dataset *Conll 2003* provided by us in the *data* folder. Please, load the files from the *data* folder and **do not** change names or paths of the inner files. \n",
    "- **Output**: for each part of your task, print your results and leave it in the notebook. Please, **do not** send a jupyter notebook without the printed outputs.\n",
    "- **Other**: follow carefully all the further instructions and suggestions given in the question descriptions.\n",
    "\n",
    "### Deadline\n",
    "The deadline is due in two weeks from the project presentation. Please, refer to *piazza* channel for the exact date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d123d",
   "metadata": {},
   "source": [
    "### Task 1: Analysis of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead0d1f",
   "metadata": {},
   "source": [
    "#### Q 1.1\n",
    "- Create the Vocabulary and Frequency Dictionary of the:\n",
    "    1. Whole dataset\n",
    "    2. Train set\n",
    "    3. Test set\n",
    "    \n",
    "**Attention**: print the first 20 words of the Dictionaty of each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca1124f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', ',', '.', 'of', 'in', 'to', 'a', '(', ')', 'and', '\"', 'on', 'said', \"'s\", 'for', '-', '1', 'at', 'was', '2']\n",
      "['the', '.', ',', 'of', 'in', 'to', 'a', 'and', '(', ')', '\"', 'on', 'said', \"'s\", 'for', '1', '-', 'at', 'was', '2']\n",
      "['the', ',', '.', 'to', 'of', 'in', '(', ')', 'a', 'and', 'on', '\"', 'said', \"'s\", '-', 'for', 'at', 'was', '4', 'with']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "from collections import Counter\n",
    "\n",
    "root = './data'\n",
    "corpus = ConllCorpusReader(root, '.txt', ('words', 'pos','tree', 'chunk'))\n",
    "whole_dataset = []\n",
    "\n",
    "test_words = [w.lower() for w in corpus.words('test.txt')]\n",
    "train_words = [w.lower() for w in corpus.words('train.txt')]\n",
    "valid_words = [w.lower() for w in corpus.words('valid.txt')]\n",
    "\n",
    "whole_dataset = test_words + train_words + valid_words\n",
    "test_plus_train = test_words + train_words\n",
    "\n",
    "test_sents = corpus.sents('test.txt')\n",
    "train_sents = corpus.sents('train.txt')\n",
    "\n",
    "whole_dataset_freq_list = Counter(whole_dataset)\n",
    "test_plus_train_freq_list = Counter(test_plus_train)\n",
    "train_freq_list = Counter(train_words)\n",
    "test_freq_list = Counter(test_words)\n",
    "\n",
    "most_twenty_whole = [ w[0] for w in (sorted(whole_dataset_freq_list.items(), key=lambda item: item[1] ,reverse= True)[:20]) ]\n",
    "print(most_twenty_whole)\n",
    "\n",
    "most_twenty_train = [ w[0] for w in (sorted(train_freq_list.items(), key=lambda item: item[1] ,reverse= True)[:20]) ]\n",
    "print(most_twenty_train)\n",
    "\n",
    "most_twenty_test = [ w[0] for w in (sorted(test_freq_list.items(), key=lambda item: item[1] ,reverse= True)[:20]) ]\n",
    "print(most_twenty_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dc02f",
   "metadata": {},
   "source": [
    "#### Q 1.2\n",
    "- Obtain the list of:\n",
    "    1. Out-Of-Vocabulary (OOV) tokens\n",
    "    2. Overlapping tokens between train and test sets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b660bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOV = set(train_words) - set(test_words)\n",
    "overlap = (set(train_words)).intersection(set(test_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1ac1c",
   "metadata": {},
   "source": [
    "#### Q 1.3\n",
    "- Perform a complete data analysis of the whole dataset (train + test sets) to obtain:\n",
    "    1. Average sentence length computed in number of tokens\n",
    "    2. The 50 most-common tokens\n",
    "    3. Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36e5c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 13.392748112045417\n",
      "\n",
      "| Most frequent 5 tokens   |   Frequence |\n",
      "|--------------------------+-------------|\n",
      "| the                      |       10155 |\n",
      "| .                        |        9000 |\n",
      "| ,                        |        8927 |\n",
      "| of                       |        4604 |\n",
      "| in                       |        4382 |\n",
      "18671\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "number_sents = len(test_sents + train_sents)\n",
    "\n",
    "# 1\n",
    "print('Average sentence length: {}'.format(len(test_words + train_words)/number_sents))\n",
    "#2\n",
    "most_frequent_tokens = sorted(test_plus_train_freq_list.items(), key=lambda item: item[1] ,reverse= True)\n",
    "print()\n",
    "print(tabulate(most_frequent_tokens[:5], headers=['Most frequent 5 tokens', 'Frequence'], tablefmt='orgtbl'))\n",
    "\n",
    "#3\n",
    "print(number_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726af097",
   "metadata": {},
   "source": [
    "#### Q 1.4\n",
    "- Create the dictionary of Named Entities and their Frequencies for the:\n",
    "    1. Whole dataset\n",
    "    2. Train set\n",
    "    3. Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1d97006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test token   |   Frequence |\n",
      "|--------------+-------------|\n",
      "| Germany      |          49 |\n",
      "| U.S.         |          45 |\n",
      "| Australia    |          45 |\n",
      "| Japan        |          41 |\n",
      "| Italy        |          41 |\n",
      "\n",
      "| Train token   |   Frequence |\n",
      "|---------------+-------------|\n",
      "| U.S.          |         303 |\n",
      "| Germany       |         141 |\n",
      "| Britain       |         133 |\n",
      "| Australia     |         130 |\n",
      "| England       |         123 |\n",
      "\n",
      "| Test and Train token   |   Frequence |\n",
      "|------------------------+-------------|\n",
      "| U.S.                   |         348 |\n",
      "| Germany                |         190 |\n",
      "| Australia              |         175 |\n",
      "| France                 |         162 |\n",
      "| England                |         144 |\n"
     ]
    }
   ],
   "source": [
    "# frequency of each Named Entities: NN, ...\n",
    "# list of all words\n",
    "\n",
    "def nbest(d):\n",
    "    return sorted(d.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "def create_dictionary_NE_frequency(file, second_file = None):\n",
    "    words = corpus.iob_words(file)\n",
    "\n",
    "    if second_file is not None:\n",
    "        words_second = corpus.iob_words(second_file)\n",
    "        words = words + words_second\n",
    "    \n",
    "    names = []\n",
    "    word = []\n",
    "\n",
    "    for entity in words:\n",
    "        if \"-\" in entity[2]:\n",
    "            prefix, suffix = entity[2].split(\"-\")\n",
    "            if prefix == \"B\":\n",
    "                names.append(' '.join(word))\n",
    "                word.clear()\n",
    "                word.append(entity[0])\n",
    "            if prefix == \"I\":\n",
    "                word.append(entity[0])\n",
    "\n",
    "    return Counter(names)\n",
    "    \n",
    "\n",
    "print(tabulate(nbest(create_dictionary_NE_frequency(\"test.txt\"))[:5], headers=['Test token', 'Frequence'], tablefmt='orgtbl'))\n",
    "print()\n",
    "print(tabulate(nbest(create_dictionary_NE_frequency(\"train.txt\"))[:5], headers=['Train token', 'Frequence'], tablefmt='orgtbl'))\n",
    "print()\n",
    "print(tabulate(nbest(create_dictionary_NE_frequency(\"train.txt\", \"test.txt\"))[:5], headers=['Test and Train token', 'Frequence'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a08f37",
   "metadata": {},
   "source": [
    "### Task 2: Working with Dependecy Tree\n",
    "*Suggestions: use Spacy pipeline to retreive the Dependecy Tree*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a40387f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sent = \"I saw the man with a telescope\"\n",
    "segment = \"with a telescope\"\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ba597",
   "metadata": {},
   "source": [
    "#### Q 2.1\n",
    "- Given each sentence in the dataset, write the required functions to provide:\n",
    "    1. Subject, obects (direct and indirect)\n",
    "    2. Noun chunks\n",
    "    3. The head noun in each noun chunk\n",
    "    \n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f6292d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal subject: 'I'\n",
      "Direct object: 'man'\n",
      "\n",
      " Noun chunk: 'I' \n",
      " Head Noun: 'I'\n",
      "\n",
      " Noun chunk: 'the man' \n",
      " Head Noun: 'man'\n",
      "\n",
      " Noun chunk: 'a telescope' \n",
      " Head Noun: 'telescope'\n"
     ]
    }
   ],
   "source": [
    "def get_subjects(doc):\n",
    "    for t in doc:\n",
    "        dep = t.dep_\n",
    "        if dep == 'nsubj': print(\"Nominal subject: '{}'\".format(t))\n",
    "        elif dep == 'dobj': print(\"Direct object: '{}'\".format(t))\n",
    "        elif dep == 'iobj': print(\"Indirect object: '{}'\".format(t))\n",
    "\n",
    "def get_noun_chunks(doc):\n",
    "    for chunk in doc.noun_chunks:\n",
    "        print(\"\\n Noun chunk: '{}' \\n Head Noun: '{}'\".format(chunk.text, chunk.root.text))\n",
    "\n",
    "get_subjects(doc)\n",
    "get_noun_chunks(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84838829",
   "metadata": {},
   "source": [
    "#### Q 2.2\n",
    "- Given a dependecy tree of a sentence and a segment of that sentence write the required functions that ouput the dependency subtree of that segment.\n",
    "\n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\" (the segment could be any e.g. \"saw the man\", \"a telescope\", etc.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b8d524e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   with  \n",
      "    |     \n",
      "telescope\n",
      "    |     \n",
      "    a    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import Tree\n",
    "import en_core_web_sm\n",
    "spacy_nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def check_leaf(node):\n",
    "    if not node.n_lefts and not node.n_rights:\n",
    "        return True\n",
    "\n",
    "# gives the index of the segment in a sentece\n",
    "def find_indexes(sentence_words, segment_words):\n",
    "    \n",
    "    results=[]\n",
    "    segment_words_len=len(segment_words)\n",
    "\n",
    "    # enumerate return two values: index and value at that index\n",
    "    for index_segment in (index for index, value in enumerate(sentence_words) if value==segment_words[0]):\n",
    "        if sentence_words[index_segment:index_segment+segment_words_len]==segment_words:\n",
    "            results.append((index_segment,index_segment+segment_words_len-1))\n",
    "\n",
    "    return results\n",
    "\n",
    "# thanks to: https://stackoverflow.com/questions/36610179/how-to-get-the-dependency-tree-with-spacy\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "# given a sentence and a segment, print the subtree of the segment\n",
    "def output_subtree(sentence, segment):\n",
    "    sentence_words = sentence.split(' ')\n",
    "    segment_words = segment.split(' ')\n",
    "    result = find_indexes(sentence_words, segment_words)\n",
    "    if len(result) < 1: raise ValueError('Segment not found') \n",
    "\n",
    "    right, left = result[0][0], result[0][1]\n",
    "\n",
    "    doc = spacy_nlp(sentence)\n",
    "\n",
    "    span = doc[doc[right].left_edge.i : doc[left].right_edge.i+1]\n",
    "    tree = to_nltk_tree(span.root)\n",
    "    if len(span) <2 and check_leaf(span): return 'The segment is a leaf'\n",
    "    return tree\n",
    "\n",
    "try:\n",
    "    res = output_subtree(sent, segment)\n",
    "    if isinstance(res, str):\n",
    "        print(res)\n",
    "    else:\n",
    "        res.pretty_print()\n",
    "            \n",
    "except ValueError as ve:\n",
    "    print(ve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e99ac",
   "metadata": {},
   "source": [
    "#### Q 2.3\n",
    "- Given a token in a sentence, write the required functions that output the dependency path from the root of the dependency tree to that given token.\n",
    "\n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b0b1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: with, path to root: ['man', 'saw']\n",
      "word: a, path to root: ['telescope', 'with', 'man', 'saw']\n",
      "word: telescope, path to root: ['with', 'man', 'saw']\n"
     ]
    }
   ],
   "source": [
    "#print the path\n",
    "\n",
    "def path_to_root(doc, segment):\n",
    "    words = segment.split()\n",
    "\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    for descendant in root.subtree:\n",
    "        if descendant.text in words:\n",
    "            print(\"word: {}, path to root: {}\".format(descendant, [ancestor.text for ancestor in descendant.ancestors]))\n",
    "\n",
    "path_to_root(doc, segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3358779",
   "metadata": {},
   "source": [
    "### Task 3: Named Entity Recognition\n",
    "*Suggestion: use scikit-learn metric functions. See classification_report*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820ad69",
   "metadata": {},
   "source": [
    "#### Q 3.1\n",
    "- Benchmark Spacy Named Entity Recognition model on the test set by:\n",
    "    1. Providing the list of categories in the dataset (person, organization, etc.)\n",
    "    2. Computing the overall accuracy on NER\n",
    "    3. Computing the performance of the Named Entity Recognition model for each category:\n",
    "        - Compute the perfomance at the token level (eg. B-Person, I-Person, B-Organization, I-Organization, O, etc.)\n",
    "        - Compute the performance at the entity level (eg. Person, Organization, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b478422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import conll\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from conll import evaluate, read_corpus_conll\n",
    "from sklearn.metrics import classification_report\n",
    "from spacy.tokenizer import Tokenizer\n",
    "sys.path.insert(0, os.path.abspath('./src/'))\n",
    "\n",
    "match = {\n",
    "    \"PERSON\": \"PER\",\n",
    "    \"GPE\": \"LOC\",\n",
    "    \"ORG\": \"ORG\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a051c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC', 'MISC', 'ORG', 'PER'}\n"
     ]
    }
   ],
   "source": [
    "def get_categories(refs):\n",
    "    categories = []\n",
    "    for sent in refs:\n",
    "        for iob in sent:\n",
    "            if \"-\" in iob:\n",
    "                iob = iob[2:]\n",
    "                categories.append(iob)\n",
    "    return categories\n",
    "\n",
    "refs_test = [[iob for text, pos, iob in sent] for sent in  corpus.iob_sents(\"test.txt\")]\n",
    "refs_train = [[iob for text, pos, iob in sent] for sent in  corpus.iob_sents(\"train.txt\")]\n",
    "refs_valid = [[iob for text, pos, iob in sent] for sent in  corpus.iob_sents(\"valid.txt\")]\n",
    "\n",
    "print(set(get_categories(refs_test) + get_categories(refs_train) + get_categories(refs_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.70      0.74      1668\n",
      "      B-MISC       0.10      0.58      0.17       702\n",
      "       B-ORG       0.50      0.28      0.36      1661\n",
      "       B-PER       0.77      0.57      0.66      1617\n",
      "       I-LOC       0.66      0.53      0.58       257\n",
      "      I-MISC       0.07      0.49      0.12       216\n",
      "       I-ORG       0.46      0.48      0.47       835\n",
      "       I-PER       0.78      0.71      0.74      1156\n",
      "           O       0.94      0.86      0.90     38323\n",
      "\n",
      "    accuracy                           0.81     46435\n",
      "   macro avg       0.56      0.58      0.53     46435\n",
      "weighted avg       0.88      0.81      0.84     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_name(iob, name):\n",
    "    if iob == 'O':\n",
    "        return 'O'\n",
    "    elif name not in match: return \"-\".join([iob, 'MISC'])\n",
    "    else:\n",
    "        return \"-\".join([iob, match.get(name)])\n",
    "\n",
    "spacy_map_token = []\n",
    "named_entity = list([(entity[0], entity[2]) for entity in corpus.iob_words(\"test.txt\")])\n",
    "sents = [sent for sent in corpus.sents(\"test.txt\")]\n",
    "\n",
    "# create blank vocab, thanks to: https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
    "for sent in sents:\n",
    "    doc = nlp(' '.join(sent))\n",
    "    for s in doc:\n",
    "        spacy_map_token.append((s.text, check_name(s.ent_iob_, s.ent_type_)))\n",
    "\n",
    "print(classification_report([en[1] for en in named_entity], [en[1] for en in spacy_map_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "31b1da40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.732</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.099</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.168</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.363</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.421</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "LOC    0.776  0.692  0.732  1668\n",
       "ORG    0.354  0.250  0.293  1661\n",
       "MISC   0.099  0.560  0.168   702\n",
       "PER    0.737  0.543  0.625  1617\n",
       "total  0.363  0.503  0.421  5648"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus  = read_corpus_conll('./data/test.txt', fs = ' ')\n",
    "\n",
    "# parsing test set\n",
    "res = []\n",
    "for sent in new_corpus:\n",
    "    doc = nlp(\" \".join([t[0] for t in sent]))\n",
    "    out = []\n",
    "    for t in doc:\n",
    "        out.append((t.text, check_name(t.ent_iob_, t.ent_type_)))\n",
    "    res.append(out)\n",
    "\n",
    "\n",
    "result = evaluate(new_corpus, res)\n",
    "pd_tb = pd.DataFrame().from_dict(result, orient='index')\n",
    "pd_tb.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669ee84",
   "metadata": {},
   "source": [
    "### Task 4: BONUS PART (extra mark for laude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56fc4f",
   "metadata": {},
   "source": [
    "#### Q 4.1\n",
    "- Modify NLTK Transition parser's Configuration calss to use better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8b182ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebf011",
   "metadata": {},
   "source": [
    "#### Q 4.2\n",
    "- Evaluate the features comparing performance to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5177f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa4657c",
   "metadata": {},
   "source": [
    "#### Q 4.3\n",
    "- Replace SVM classifier with an alternative of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b94966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
